{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analyzing the dataset**\n",
    "\n",
    "This python notebook analyzes the `housing.csv` dataset to determine the various transformation to be done to transform the data into a format suitable for training the machine learning model (linear regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 545 row(s) and 13 column(s).\n",
      "Information about the dataset is displayed below:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   price             545 non-null    int64 \n",
      " 1   area              545 non-null    int64 \n",
      " 2   bedrooms          545 non-null    int64 \n",
      " 3   bathrooms         545 non-null    int64 \n",
      " 4   stories           545 non-null    int64 \n",
      " 5   mainroad          545 non-null    object\n",
      " 6   guestroom         545 non-null    object\n",
      " 7   basement          545 non-null    object\n",
      " 8   hotwaterheating   545 non-null    object\n",
      " 9   airconditioning   545 non-null    object\n",
      " 10  parking           545 non-null    int64 \n",
      " 11  prefarea          545 non-null    object\n",
      " 12  furnishingstatus  545 non-null    object\n",
      "dtypes: int64(6), object(7)\n",
      "memory usage: 55.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"housing.csv\", parse_dates=True)\n",
    "row_count = dataset.shape[0]\n",
    "column_count = dataset.shape[1]\n",
    "print(f\"Dataset has {row_count} row(s) and {column_count} column(s).\")\n",
    "print(\"Information about the dataset is displayed below:\")\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum and minimum price values are $13,300,000 and $1,750,000 respectively.\n",
      "The maximum and minimum area are 16200 and 1650 respectively.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The maximum and minimum price values are ${dataset['price'].max():,} and ${dataset['price'].min():,} respectively.\")\n",
    "print(f\"The maximum and minimum area are {dataset['area'].max():,} and {dataset['area'].min():,} respectively.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- All 545 rows have non-null values and so null-cleanup is not required.\n",
    "- Since the price value in the dataset is atleast 1.75 millions, dividing all the values in the dataset by 1 million will give us a relatively lesser scale of values to train our model with, making it less computabionally intensive.\n",
    "- Since the area is atlease 1650, we can divide all the area values by 1000, to simplify computations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlforge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
